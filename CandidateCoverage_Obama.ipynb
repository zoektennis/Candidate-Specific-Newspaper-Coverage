{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a37ca47c-dcc5-452c-ab58-bea7b28afb91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classification of headlines mentioning \"Obama\" using 1)Support Model and 2) Performance Model\n",
    "# Original model: mlburnham/Political_DEBATE_DeBERTa_large_v1.1 on huggingface\n",
    "# Further trained on sample of candidate related headlines\n",
    "\n",
    "\n",
    "#: zkava01/AuthorSupport_Oct29 on huggingface\n",
    "#: zkava1/AuthorPerformance_Oct29 on huggingface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5a277d36-0790-4e9f-8cfe-11c6c18a3709",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import re\n",
    "from transformers import pipeline\n",
    "from tqdm import tqdm  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c6fdb890-2c98-4e3a-873c-9ed95099b517",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct Dropbox path\n",
    "dropbox_path = os.path.expanduser(\"FILEHERE.csv\")\n",
    "\n",
    "# Load the CSV file\n",
    "df = pd.read_csv(dropbox_path, low_memory=False)\n",
    "\n",
    "# Convert \"Date\" to datetime format \n",
    "df[\"date\"] = pd.to_datetime(df[\"date\"], errors=\"coerce\")\n",
    "\n",
    "# Here is where you can filter for the particular election year, or years you want #\n",
    "# Here we'll restrict to articles from election day 2007 to election day 2016 \n",
    "start_date = \"2007-11-01\"\n",
    "end_date = \"2016-11-15\"\n",
    "df = df[(df[\"date\"] >= start_date) & (df[\"date\"] <= end_date)]\n",
    "\n",
    "# Define the list of political figures with their last names\n",
    "figures_full = {\n",
    "    \"Harry Truman\": [\"Truman\"],\n",
    "    \"Thomas Dewey\": [\"Dewey\"],\n",
    "    \"Strom Thurmond\": [\"Thurmond\"],\n",
    "    \"Dwight Eisenhower\": [\"Eisenhower\"],\n",
    "    \"Adlai Stevenson\": [\"Stevenson\"],\n",
    "    \"John F. Kennedy\": [\"Kennedy\"],\n",
    "    \"Richard Nixon\": [\"Nixon\"],\n",
    "    \"Lyndon B. Johnson\": [\"Johnson\"],\n",
    "    \"Barry Goldwater\": [\"Goldwater\"],\n",
    "    \"Hubert Humphrey\": [\"Humphrey\"],\n",
    "    \"George Wallace\": [\"Wallace\"],\n",
    "    \"George McGovern\": [\"McGovern\"],\n",
    "    \"Jimmy Carter\": [\"Carter\"],\n",
    "    \"Gerald Ford\": [\"Ford\"],\n",
    "    \"Ronald Reagan\": [\"Reagan\"],\n",
    "    \"John B. Anderson\": [\"Anderson\"],\n",
    "    \"Walter Mondale\": [\"Mondale\"],\n",
    "    \"George H.W Bush\": [\"Bush\"],\n",
    "    \"Michael Dukakis\": [\"Dukakis\"],\n",
    "    \"Bill Clinton\": [\"Clinton\"],\n",
    "    \"Ross Perot\": [\"Perot\"],\n",
    "    \"Bob Dole\": [\"Dole\"],\n",
    "    \"Al Gore\": [\"Gore\"],\n",
    "    \"John Kerry\": [\"Kerry\"],\n",
    "    \"Barack Obama\": [\"Obama\"],\n",
    "    \"John McCain\": [\"McCain\"],\n",
    "    \"Mitt Romney\": [\"Romney\"],\n",
    "    \"Donald Trump\": [\"Trump\"],\n",
    "    \"Joe Biden\": [\"Biden\"],\n",
    "    \"Kamala Harris\": [\"Harris\"]\n",
    "}\n",
    "\n",
    "# Create a mapping for last names to their full figure name\n",
    "last_name_to_full = {alt.lower(): full for full, alts in figures_full.items() for alt in alts}\n",
    "\n",
    "# match full names and last names (case insensitive)\n",
    "figure_pattern = r'\\b(?:' + '|'.join(re.escape(name) for name in last_name_to_full.keys()) + r')\\b'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0c65bcf4-206a-4adc-8417-fcd1f78a349a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Rebuild the regex pattern \n",
    "figure_pattern = r'\\b(?:' + '|'.join(re.escape(name) for name in last_name_to_full.keys()) + r')\\b'\n",
    "\n",
    "# Choose the figures you're interested in\n",
    "key_figures = [\"Barack Obama\"]  # or [\"Donald Trump\", \"Joe Biden\", \"Kamala Harris\", ...]\n",
    "\n",
    "# Expand into long format. one row per (headline, matched figure)\n",
    "records = []\n",
    "for _, row in df.iterrows():\n",
    "    title = str(row[\"title\"])\n",
    "    found = re.findall(figure_pattern, title, flags=re.IGNORECASE)\n",
    "    for match in set(found):  # unique matches only\n",
    "        full_name = last_name_to_full[match.lower()]\n",
    "        if full_name in key_figures:\n",
    "            record = row.copy()\n",
    "            record[\"figure\"] = full_name  # <-- this replaces 'figure1'\n",
    "            records.append(record)\n",
    "\n",
    "# Final long-format dataframe for classification\n",
    "df_filtered = pd.DataFrame(records)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c913d79a-a04d-4665-8d93-13fe91d2f7db",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Updated loop with new models - Support and Performance ####\n",
    "\n",
    "# Load both classifiers\n",
    "support_classifier = pipeline(\n",
    "    \"zero-shot-classification\",\n",
    "    model=\"zkava01/AuthorSupport_Oct29\",\n",
    "    tokenizer=\"zkava01/AuthorSupport_Oct29\"\n",
    ")\n",
    "\n",
    "performance_classifier = pipeline(\n",
    "    \"zero-shot-classification\",\n",
    "    model=\"zkava01/AuthorPerformance_Oct29\",\n",
    "    tokenizer=\"zkava01/AuthorPerformance_Oct29\"\n",
    ")\n",
    "\n",
    "# Hypothesis templates\n",
    "support_hypotheses_template = [\n",
    "    \"The author of this text supports {}\",\n",
    "    \"The author of this text does not support {}\"\n",
    "]\n",
    "\n",
    "performance_hypotheses_template = [\n",
    "    \"The author of this text believes {} is performing/performed/will perform well\",\n",
    "    \"The author of this text believes {} is performing/performed/will perform poorly\"\n",
    "]\n",
    "\n",
    "# Chunk setup\n",
    "chunk_size = 500\n",
    "num_chunks = (len(df_filtered) // chunk_size) + 1\n",
    "output_dir = \"OUTPUTHERE\"\n",
    "chunk_dir = os.path.join(output_dir, \"chunks\")\n",
    "output_base = \"Obama\"\n",
    "os.makedirs(chunk_dir, exist_ok=True)\n",
    "\n",
    "merged_chunks = []\n",
    "\n",
    "print(f\"Running support and performance classification in {num_chunks} chunks...\")\n",
    "\n",
    "for i in range(num_chunks):\n",
    "    start_idx = i * chunk_size\n",
    "    end_idx = min((i + 1) * chunk_size, len(df_filtered))\n",
    "    chunk = df_filtered.iloc[start_idx:end_idx].copy()\n",
    "\n",
    "    # Add output columns\n",
    "    chunk[\"debate_support\"] = \"NA\"\n",
    "    chunk[\"debate_performance\"] = \"NA\"\n",
    "\n",
    "    for idx, row in tqdm(chunk.iterrows(), total=len(chunk), desc=f\"Chunk {i+1}/{num_chunks}\"):\n",
    "        title = row[\"title\"]\n",
    "        figure = row[\"figure\"]\n",
    "\n",
    "        if figure in key_figures:\n",
    "            # Author Support \n",
    "            support_hypotheses = [h.format(figure) for h in support_hypotheses_template]\n",
    "            support_output = support_classifier(title, support_hypotheses, multi_label=True)\n",
    "            support_scores = dict(zip(support_output[\"labels\"], support_output[\"scores\"]))\n",
    "\n",
    "            if support_scores.get(support_hypotheses[0], 0) > 0.99:\n",
    "                chunk.at[idx, \"debate_support\"] = 1\n",
    "            elif support_scores.get(support_hypotheses[1], 0) > 0.99:\n",
    "                chunk.at[idx, \"debate_support\"] = -1\n",
    "            else:\n",
    "                chunk.at[idx, \"debate_support\"] = 0\n",
    "\n",
    "            # Author Performance \n",
    "            performance_hypotheses = [h.format(figure) for h in performance_hypotheses_template]\n",
    "            perf_output = performance_classifier(title, performance_hypotheses, multi_label=True)\n",
    "            perf_scores = dict(zip(perf_output[\"labels\"], perf_output[\"scores\"]))\n",
    "\n",
    "            if perf_scores.get(performance_hypotheses[0], 0) > 0.5:\n",
    "                chunk.at[idx, \"debate_performance\"] = 1\n",
    "            elif perf_scores.get(performance_hypotheses[1], 0) > 0.5:\n",
    "                chunk.at[idx, \"debate_performance\"] = -1\n",
    "            else:\n",
    "                chunk.at[idx, \"debate_performance\"] = 0\n",
    "\n",
    "    # Save chunk\n",
    "    chunk_filename = f\"{output_base}_chunk{i+1}.csv\"\n",
    "    chunk_path = os.path.join(chunk_dir, chunk_filename)\n",
    "    chunk.to_csv(chunk_path, index=False)\n",
    "    print(f\"Saved {chunk_filename}\")\n",
    "    merged_chunks.append(chunk)\n",
    "\n",
    "# Merge and save all chunks\n",
    "final_df = pd.concat(merged_chunks, ignore_index=True)\n",
    "final_output_path = os.path.join(output_dir, \"ObamaHeadlines.csv\")\n",
    "final_df.to_csv(final_output_path, index=False)\n",
    "print(f\"Saved final combined file: {final_output_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5909b20-d0b9-4b2d-be89-ed9a016ba727",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
